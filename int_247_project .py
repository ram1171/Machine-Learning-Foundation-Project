# -*- coding: utf-8 -*-
"""INT 247 Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wbaxSw7VUQF1XJNzmegY75goIC9tj2VK
"""

#from google.colab import files
#uploaded = files.upload()

import pandas as pd
import numpy as np                     
import seaborn as sns                  
import matplotlib.pyplot as plt 
import seaborn as sn                  
# %matplotlib inline
import warnings                     
warnings.filterwarnings("ignore")

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')

train.columns

test.columns

train.shape,test.shape

train.dtypes

test.dtypes

train.head()

train.isnull().sum()

train['subscribed'].value_counts()

train['subscribed'].value_counts(normalize=True)

train['subscribed'].value_counts().plot.bar()

sn.distplot(train["age"])

train['job'].value_counts().plot.bar()

train['default'].value_counts().plot.bar()

print(pd.crosstab(train['job'],train['subscribed']))

job=pd.crosstab(train['job'],train['subscribed'])
job.div(job.sum(1).astype(float), axis=0).plot(kind="bar", stacked=True, figsize=(8,8))
plt.xlabel('Job')
plt.ylabel('Percentage')

print(pd.crosstab(train['default'],train['subscribed']))

default=pd.crosstab(train['default'],train['subscribed'])
default.div(default.sum(1).astype(float), axis=0).plot(kind="bar", stacked=True, figsize=(8,8))
plt.xlabel('default')
plt.ylabel('Percentage')

train['subscribed'].replace('no', 0,inplace=True)
train['subscribed'].replace('yes', 1,inplace=True)
print(train['subscribed'].head())

corr = train.corr()
mask = np.array(corr)
mask[np.tril_indices_from(mask)] = False
fig,ax= plt.subplots()
fig.set_size_inches(20,10)
sn.heatmap(corr, mask=mask,vmax=.9, square=True,annot=True, cmap="YlGnBu")

target = train['subscribed']
train = train.drop('subscribed',1)

train = pd.get_dummies(train)

from sklearn.model_selection import train_test_split

xtrain,xtest, ytrain, ytest = train_test_split(train, target, test_size = 0.2, random_state=12)

from sklearn.linear_model import LogisticRegression

lreg = LogisticRegression(penalty='l2')
lreg.fit(xtrain,ytrain)
prediction = lreg.predict(xtest)

from sklearn.metrics import accuracy_score
print('Logistic Regression')
print(accuracy_score(ytest, prediction))

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(max_depth=4, random_state=0)
clf.fit(xtrain,ytrain)
predict = clf.predict(xtest)
print('Decision Tree')
print(accuracy_score(ytest, predict))

from sklearn.ensemble import RandomForestClassifier
forest=RandomForestClassifier(criterion='gini',n_estimators=50,random_state=1,n_jobs=2)
forest.fit(xtrain,ytrain)
pred=forest.predict(xtest)
print('Random Forest')
print(accuracy_score(ytest,pred))

print('Hyper Parameter Tuning')
f1=RandomForestClassifier(criterion='gini',n_estimators=70,random_state=1,n_jobs=2)
f1.fit(xtrain,ytrain)
pred1=f1.predict(xtest)
print('Random Forest after Hyper Parameter Tuning 1')
print(accuracy_score(ytest,pred1))
f2=RandomForestClassifier(criterion='gini',n_estimators=90,random_state=1,n_jobs=2)
f2.fit(xtrain,ytrain)
pred2=f2.predict(xtest)
print('Random Forest after Hyper Parameter Tuning 2')
print(accuracy_score(ytest,pred2))
f3=RandomForestClassifier(criterion='gini',n_estimators=100,random_state=1,n_jobs=2)
f3.fit(xtrain,ytrain)
pred3=f3.predict(xtest)
print('Random Forest after Hyper Parameter Tuning 3')
print(accuracy_score(ytest,pred3))


#from google.colab import files
#uploaded1 = files.upload()

test = pd.get_dummies(test)
test_prediction = forest.predict(test)
submission = pd.DataFrame()
submission['ID'] = test['ID']
submission['subscribed'] = test_prediction
submission['subscribed'].replace(0,'no',inplace=True)
submission['subscribed'].replace(1,'yes',inplace=True)
submission.to_csv('submission.csv', header=True, index=False)